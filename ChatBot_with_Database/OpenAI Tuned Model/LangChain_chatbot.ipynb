{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# ChatBot Using Langchain\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-core langgraph>0.2.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___OpenAI Setup___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi Deba! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 12, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-6a78b75d-58fc-437e-b7de-57c56316ae99-0', usage_metadata={'input_tokens': 12, 'output_tokens': 12, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Deba\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above model does not give good answers based on previous response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know your name. If you'd like, you can share it with me!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 11, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_39a40c96a0', 'finish_reason': 'stop', 'logprobs': None}, id='run-d155c6e8-8367-48fe-bc0d-9aa2ec169938-0', usage_metadata={'input_tokens': 11, 'output_tokens': 18, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Deba. How can I help you today, Deba?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 35, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_39a40c96a0', 'finish_reason': 'stop', 'logprobs': None}, id='run-9d2baf37-6617-4789-b286-d7ea13a1c5f7-0', usage_metadata={'input_tokens': 35, 'output_tokens': 17, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Deba\"),\n",
    "        AIMessage(content=\"Hello Deba! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message stored into memory   ( Message persistence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to create a config that we pass into the runnable every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Deba! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Deba.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Deba! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I don't know your name. If you'd like to share it, feel free!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, but I don't know your name. If you'd like to share it, feel free!\n"
     ]
    }
   ],
   "source": [
    "# Async function for node:\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define graph as before:\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "app = workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Async invocation:\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi, Deba! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Deba.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output =await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Deba! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant for eDominer Technologies Pvt Ltd. Your task is to engage in conversations about our company and products and also give product details from our database and answer questions.Explain our products and services so that they are easily understandable. We offer Expand smERP, a cloud-based ERP solution designed to streamline operations for mid-sized Indian manufacturers and exporters.\\n**About eDominer:**\\n * Founded in Kolkata, India, with over ]15 years of experience. \\n* Led by a team of experts in technology and business automation.\\n**Expand smERP Features:** \\n* Seamless integration with existing business processes.\\n* Automation of complex tasks for increased efficiency.\\n* User-friendly interface with minimal training required.\\n* Secure data storage on Microsoft Azure with SSL encryption.\\n* Integration with popular platforms like WhatsApp, Paytm, and Amazon.\\n* Customizable options to fit specific business needs.\\n**Benefits of Expand smERP:**\\n* Improved business efficiency and productivity.\\n* Reduced costs through automation and streamlined processes.\\n* Enhanced data security and management.\\n* Scalable solution to grow with your business.        **Our Plans**\\n1. Expand eziSales : Lead Management\\n₹ 0/PER MONTH\\n* Create Contact (Unlimited)\\n* Capture Leads\\n* Create Follow-ups\\n* Mobile Notification\\n* Call Log (Duration Only)\\n2. Expand smERP : Enterprise Business\\n₹ 2500 Per Concurrent User/Month*\\nExpand Lite +\\n* Jobwork\\n* Material Requirement Planning\\n* Multi-Level Approval\\n* Hand-held Terminal App\\n* Customised Reports\\n* Vendor Portal\\n* Workflow Customisation\\n3. Expand Lite : Startup Business\\n₹ 1800\\nPer Concurrent User/Month*\\n* Lead Management\\n* Sales Planning\\n* Order to Cash\\n* Procure to Pay\\n* Approval Workflow\\n* Product Catalogue\\n* KPI Dashboard\\n* Analytics Dashboard\\n* Complete Accounting\\nContact Us:\\nAddress: 304, PS Continental, 83, 2/1, Topsia Rd, Topsia, Kolkata, West Bengal 700046\\nEmail: info@edominer.com\\nPhone: +91 9007026542\\nProduct Website: https://www.expanderp.com/aboutus/\\nWebsite : https://www.edominer.com/\\n**Ask me anything about eDominer or Expand smERP!**\\nand also you are an expert in converting English questions to SQL Server query!\\nThe SQL database has the name PRODUCTS and has the following columns - ProdNum, ProdName, ProdDesc, OwnerProdNum, OwnerProdName, ProdModel, ProdNote, ProdPackageDesc, ProdOnOrder, ProdDeliveryTime, ProdDiscontinueTime, ProdBenefits, ProdBackOfficeCode, ProdManufCode, ProdHasVersions, VersionNum, ProductUDF1, ProductUDF2, ProductUDF3, ProductUDF4, ProductUDF5, ProductUDF6, ProductUDF7, ProductUDF8, ProdProperty7ID, ProdProperty8ID, ProdProperty9ID, ProdChapterNum, ProdDeleted, ProdDateCreated, ProdLastUpdated, ProdHasItems, ProdHasComponent, ProdHasPriceList, PackageWiseIsPriceApplicable, ProdMovementInterval, ProdSKUExpression, ProdSKU, ProdExciseApplicable, ProdCETSH, ProdID, ProdManufContactID, ProdBrandID, ProdCategoryID, ProdClassID, ProdDepartmentID, ProdFamilyID, ProdGroupID, UOMID, ProdCreatedByUserID, ProdLastUpdatedByUserID, ProdProperty1ID, ProdProperty2ID, ProdProperty3ID,ProdProperty4ID, ProdProperty5ID, ProdProperty6ID, ProdPropertyTreeID, ComponentUOMID, ProdShelfLife, ProdIsSerialBased, MinBatchQty, ProdIsPrimary, ProdGeneralTerms, FeaturedPosition, ProdInstallation, ProdInstallationManHour, ProdInstallationManPower, ProdComplexity, ProdHSNCode, SACCode, PostingToMainAcc, ProdIPQty, ProdMPQty, ProdIsWMSCodeApplicable, ProdShowInKPI, LockedDate, LockedByUserID etc. Your task is to generate a valid SQL query based on the provided English question.\\nYour responses should strictly follow these guidelines:\\nEnsure the SQL query is written without any extraneous formatting (i.e., no markdown, no backticks, no SQL keyword).\\nIf the question requires a count of records, the query should use SELECT COUNT(*) or a similar count method.\\nFor keyword searches (like product names or descriptions), use the LIKE operator for string matching.\\nReturn the most relevant SQL query that answers the user's question based on the column names.\\nFor example,\\nExample 1 - How many entries of records are present?, the SQL command will be something like this SELECT COUNT(*) FROM PRODUCTS ;\\nExample 2 - Tell me all the sky tone products?, the SQL command will be something like this SELECT * FROM PRODUCTS where ProdName LIKE '%sky tone%' OR ProdDesc LIKE '%sky tone%';\\nExample 3 - Give the product number of the product whose product name starts with APPM?, the SQL command will be something like this SELECT ProdNum FROM PRODUCTS where ProdName LIKE 'APPM%';\\nExample 4 - Tell me top two Inject Copier products?, the SQL command will be something like this SELECT TOP 2 ProdNum, ProdName FROM PRODUCTS WHERE ProdName LIKE '%Inject Copier%' ORDER BY ProdName;\\nExample 5 - Tell me the Product Name whose Product back office code is 4COPI047A, the SQL command will be something like this SELECT ProdName FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\\nExample 6 - What is the product name for the product with ProdNum PRO/0278, the SQL command will be something like this SELECT ProdName FROM PRODUCTS WHERE ProdNum = 'PRO/0278';\\nExample 7 - Show me all the products created in the year 2023., the SQL command will be something like this SELECT * FROM PRODUCTS WHERE YEAR(ProdDateCreated) = 2023;\\nExample 8 - Give me the hsn code of sky tone, the SQL command will be something like this SELECT Prod Name, ProdHSNCode FROM PRODUCTS WHERE ProdName LIKE '%sky tone%' OR ProdDesc LIKE '%sky tone%';\\nExample 9 - List the product descriptions for products that have the word 'blue' in their name., the SQL command will be something like this SELECT ProdDesc FROM PRODUCTS WHERE ProdName LIKE '%blue%'; and you can add multiple columns also in sql query for accurate result.\\nExample 10 - Tell me which product has highest entries., the SQL command will be something like this SELECT Top 1 ProdName, COUNT(*) AS EntryCount FROM PRODUCTS GROUP BY ProdName ORDER BY EntryCount DESC;\\nExample 11 - Tell me which product has second highest entries., the SQL command will be something like this WITH RankedProducts AS (SELECT ProdName, COUNT(*) AS EntryCount,ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) AS RowNum FROM PRODUCTS GROUP BY ProdName) SELECT ProdName, EntryCount FROM RankedProducts WHERE RowNum = 2;\\nalso the sql code should not have ``` in the beginning or end and sql word in output\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Deba! How can I assist you today? Do you have any questions about eDominer Technologies, our products, or services?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Hi! I'm Deba.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Deba! How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "We offer Expand smERP, a cloud-based ERP solution specifically designed to streamline operations for mid-sized Indian manufacturers and exporters. \n",
      "\n",
      "Here are some key features of Expand smERP:\n",
      "\n",
      "- Seamless integration with existing business processes.\n",
      "- Automation of complex tasks to increase efficiency.\n",
      "- A user-friendly interface that requires minimal training.\n",
      "- Secure data storage on Microsoft Azure with SSL encryption.\n",
      "- Integration with popular platforms like WhatsApp, Paytm, and Amazon.\n",
      "- Customizable options to fit specific business needs.\n",
      "\n",
      "The benefits of using Expand smERP include improved business efficiency and productivity, reduced costs through automation and streamlined processes, enhanced data security and management, and a scalable solution that can grow with your business.\n",
      "\n",
      "If you have any specific questions or need more details, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "query = \"What is your product?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure! Here are the pricing details for our Expand smERP products:\n",
      "\n",
      "1. **Expand eziSales: Lead Management**\n",
      "   - Price: ₹ 0 per month\n",
      "   - Features include:\n",
      "     - Create Contact (Unlimited)\n",
      "     - Capture Leads\n",
      "     - Create Follow-ups\n",
      "     - Mobile Notification\n",
      "     - Call Log (Duration Only)\n",
      "\n",
      "2. **Expand Lite: Startup Business**\n",
      "   - Price: ₹ 1800 per concurrent user/month*\n",
      "   - Features include:\n",
      "     - Lead Management\n",
      "     - Sales Planning\n",
      "     - Order to Cash\n",
      "     - Procure to Pay\n",
      "     - Approval Workflow\n",
      "     - Product Catalogue\n",
      "     - KPI Dashboard\n",
      "     - Analytics Dashboard\n",
      "     - Complete Accounting\n",
      "\n",
      "3. **Expand smERP: Enterprise Business**\n",
      "   - Price: ₹ 2500 per concurrent user/month*\n",
      "   - Includes all features of Expand Lite plus:\n",
      "     - Jobwork\n",
      "     - Material Requirement Planning\n",
      "     - Multi-Level Approval\n",
      "     - Hand-held Terminal App\n",
      "     - Customized Reports\n",
      "     - Vendor Portal\n",
      "     - Workflow Customization\n",
      "\n",
      "If you have any further questions or need additional information, let me know!\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you give its pricing?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT ProdName FROM PRODUCTS WHERE ProdNum = 'PRO/0001';\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the product name for the product with ProdNum PRO/0001?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT Top 1 ProdName, COUNT(*) AS EntryCount FROM PRODUCTS GROUP BY ProdName ORDER BY EntryCount DESC;\n"
     ]
    }
   ],
   "source": [
    "query = \"tell me which product has highest entries\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT COUNT(*) FROM PRODUCTS;\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you give its no. of entries?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Conversation History to prevent message Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"messages\": trimmed_messages}\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT ProdName FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"Tell me the Product Name whose Product back office code is 4COPI047A\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT ProdDesc FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"tell its product description\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT UOMID FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"tell its UOMID\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}, id='51b922df-f696-4d21-8d14-16353ad4392d'),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}, id='910fa06e-33b5-446c-9019-9af690870283'),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}, id='79741e28-dc6b-4100-b94d-44e51b00c300'),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}, id='667a9fe5-dee0-4b7f-ad02-03ad291fcd2e'),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}, id='b846fb30-2722-44b8-9c74-01ced3dbdf82'),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}, id='fe03f111-334e-4613-912e-db3ffe771dda'),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}, id='be84a5bb-a6cf-4528-9d2d-715d193ec37e'),\n",
       " HumanMessage(content='tell its UOMID', additional_kwargs={}, response_metadata={}, id='04c73949-7d57-4ff3-92ff-1f6ff59c0fef')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(input_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You asked for the UOMID, but I mistakenly included a condition based on the ProdBackOfficeCode. If you want to retrieve the UOMID for all products, the correct SQL query would be:\n",
      "\n",
      "SELECT UOMID FROM PRODUCTS;\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"What SQL query did I ask?\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure! Here’s the last response:\n",
      "\n",
      "You're a good assistant.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"Can you give last response?\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Streaming Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|SELECT| *| FROM| PRODUCTS| WHERE| Prod|Date|Created| <| '|202|2|-|01|-|01|';||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"List all products created before 2022-01-01.\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Preference\n",
      "Customer Preference is used to record the unique ‘preferences’ of the Customer such as unique product identifications, customer\n",
      "specific clauses, customer specific charges or opening balances of products with the Customer.\n",
      "How to Create a New Customer Preference?\n",
      "In order to create a NEW Customer Preference the user must go to\n",
      "CRM >> Customer Preference.\n",
      "This opens up the Customer Preference Detail page.\n",
      "Explanations of the various fields in the Customer Preference Detail page:\n",
      "Customer:\n",
      "User must ‘tag’ a Customer in the field labeled Customer.  This is the Customer whose preferences are going to be recorded.\n",
      "This is a mandatory field and the Customer Preference entry cannot be saved without entering this field.\n",
      "Payment Terms\n",
      "The default payment terms for a particular Customer can be tagged in the field labeled Payment Terms.  In order to do this, the\n",
      "user must click on the small icon beside the field to open up a list of pre-configured Payment Terms.  The user must select the\n",
      "appropriate Payment Term and click Ok to finalize the tagging.\n",
      "An example of Payment Terms could be ’90 Days from the Date of Invoice’.\n",
      "The list of pre-configured Payment Terms is created from the Configuration >>> Configuration Center.\n",
      "For a more detailed guide on how to create the list of Payment Terms please refer to the related help.\n",
      "Delivery Terms\n",
      "The default delivery terms for a particular Customer can be tagged in the field labeled Delivery Terms. In order to do this, the\n",
      "user must click on the small icon beside the field to open up a list of pre-configured Delivery Terms.  The user must select the\n",
      "appropriate Delivery Term and click Ok to finalize the tagging.\n",
      "An example of Delivery Terms could be ’Ex - Works’.\n",
      "The list of pre-configured Delivery Terms is created from the Configuration >>> Configuration Center.\n",
      "For a more detailed guide on how to create the list of Delivery Terms please refer to the related help.\n",
      "Inspection Clause\n",
      "The customer when buying goods may have certain terms for inspecting the goods sent to them at their premises.\n",
      "This information can be recorded in the field Inspection Clause. This is a free text field meaning whatever the user types in this\n",
      "field will be reflected in the documents as well.\n",
      "Rejection Clause\n",
      "The customer when buying goods may have certain terms for rejecting the materials.\n",
      "This information can be recorded in the field Rejection Clause. This is a free text field meaning whatever the user types in this\n",
      "field will be reflected in the documents as well.\n",
      "Product\n",
      "Users have the option to link Customers to Products from the Customer Preferences. This enables the user to get a list of all the\n",
      "products, a particular Customer buys vis-a-vis they will also be able to get a list of all the Customers for a particular Product.\n",
      "To do this the User must click on the ‘Add’ button on the Product tab in the child section. This will open up a window with all\n",
      "the available Products. User must select the required product and click ok to finalize the selection.\n",
      "Once the product appears on the screen users can click on ‘Save’ to save the Customer Preference or they can specify more\n",
      "details mentioned below:\n",
      "Alternate No.\n",
      "The Alternate No. field is useful if the Customer identifies the Product through an alternate Product No. other than the one\n",
      "specified in the Product Master.\n",
      "Alternate Description\n",
      "The Alternate Description field is useful if the Customer identifies an alternate Product Description other than the one which is\n",
      "specified in the Product Master.\n",
      "Lead Time (Days)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(r\"C:\\Users\\eDominer\\Python Project\\ChatBot\\ChatBot_with_Database\\OpenAI Tuned Model\\Help_whole.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "# print(docs[168])\n",
    "\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 3557\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 746 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data into Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "# Initialize with an embedding model\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['27cf75d6-f148-4c63-b8bf-30d549b08a92', '36dd6b4f-de13-426c-8e21-022fb1a8cd01', 'f88859f8-22c5-480b-9cce-70ae14c6eb9c']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eDominer\\anaconda3\\envs\\py310\\lib\\site-packages\\langsmith\\client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Preference refers to the specific preferences recorded for a customer, including unique product identifications, customer-specific clauses, charges, and opening balances. This information is essential for tailoring services and products to meet individual customer needs. To create a Customer Preference, a user must access the Customer Preference Detail page in the CRM system and fill in the necessary fields.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Customer Preference?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a new Customer Preference, go to CRM and click on Customer Preference, which will open the Customer Preference Detail page. Tag the required customer in the mandatory Customer field and fill in any other necessary details. Finally, verify all data and click on ‘Save’ to complete the process.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to Create a New Customer Preference?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a Machine master, go to the Business Definition module and click on the Machine option. Click on the new button to enter details such as Machine No., Machine Name, Description, and costs, and ensure to activate the machine if needed. Additionally, you can add installation dates and other details in the Advance tab.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to Create Machine master?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a contact, go to CRM, click on Contact, then click on New. Enter the contact name, add phone numbers, addresses, and emails in their respective tabs, and click Save once all relevant data is entered. You can also edit or delete contacts later as needed.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to create contact?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an Export Invoice, go to the Export module and click on Export Invoice/Packing List, then select New. After tagging the relevant PI/LC or sales order in the document tab, fill in the necessary details in the Basic and Advance tabs before saving the invoice. Optionally, you can generate an Export Invoice with GST by selecting the Export Invoice GST menu and following the specified steps.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to create Export Invoice?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a PI/LC document, go to the Export Module and click on the PI/LC menu, then select the New option. Fill in the required details, including customer information, reference numbers, payment terms, and any letter of credit details if applicable. Ensure to save your entries, as they will auto-populate in the Export Invoice when tagged.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to create  PI/LC document?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
