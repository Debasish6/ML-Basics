{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# ChatBot Using Langchain\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-core langgraph>0.2.27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ___OpenAI Setup___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(api_key =os.getenv(\"OPENAI_API_KEY\"),temperature=0,model=\"gpt-4o-mini\")\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Deba! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 13, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4b973825-6152-49ec-b8b2-f53651986349-0', usage_metadata={'input_tokens': 13, 'output_tokens': 12, 'total_tokens': 25, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Deba\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above model does not give good answers based on previous response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I do not have access to personal information such as your name.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 12, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-163af73c-cc12-46c7-a249-07740c431ab2-0', usage_metadata={'input_tokens': 12, 'output_tokens': 17, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Deba. How can I assist you today, Deba?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 37, 'total_tokens': 53, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-320e7b18-4241-4d8c-8391-0341ce3da82e-0', usage_metadata={'input_tokens': 37, 'output_tokens': 16, 'total_tokens': 53, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Deba\"),\n",
    "        AIMessage(content=\"Hello Deba! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message stored into memory   ( Message persistence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to create a config that we pass into the runnable every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Deba! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Deba.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Deba.\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, I do not have access to personal information such as your name. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, I don't have access to that information.\n"
     ]
    }
   ],
   "source": [
    "# Async function for node:\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define graph as before:\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "app = workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Async invocation:\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Deba! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm Deba.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output =await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Deba. How can I assist you today, Deba?\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI assistant for eDominer Technologies Pvt Ltd. Your task is to engage in conversations about our company and products and also give product details from our database and answer questions.Explain our products and services so that they are easily understandable. We offer Expand smERP, a cloud-based ERP solution designed to streamline operations for mid-sized Indian manufacturers and exporters.\\n**About eDominer:**\\n * Founded in Kolkata, India, with over ]15 years of experience. \\n* Led by a team of experts in technology and business automation.\\n**Expand smERP Features:** \\n* Seamless integration with existing business processes.\\n* Automation of complex tasks for increased efficiency.\\n* User-friendly interface with minimal training required.\\n* Secure data storage on Microsoft Azure with SSL encryption.\\n* Integration with popular platforms like WhatsApp, Paytm, and Amazon.\\n* Customizable options to fit specific business needs.\\n**Benefits of Expand smERP:**\\n* Improved business efficiency and productivity.\\n* Reduced costs through automation and streamlined processes.\\n* Enhanced data security and management.\\n* Scalable solution to grow with your business.        **Our Plans**\\n1. Expand eziSales : Lead Management\\n₹ 0/PER MONTH\\n* Create Contact (Unlimited)\\n* Capture Leads\\n* Create Follow-ups\\n* Mobile Notification\\n* Call Log (Duration Only)\\n2. Expand smERP : Enterprise Business\\n₹ 2500 Per Concurrent User/Month*\\nExpand Lite +\\n* Jobwork\\n* Material Requirement Planning\\n* Multi-Level Approval\\n* Hand-held Terminal App\\n* Customised Reports\\n* Vendor Portal\\n* Workflow Customisation\\n3. Expand Lite : Startup Business\\n₹ 1800\\nPer Concurrent User/Month*\\n* Lead Management\\n* Sales Planning\\n* Order to Cash\\n* Procure to Pay\\n* Approval Workflow\\n* Product Catalogue\\n* KPI Dashboard\\n* Analytics Dashboard\\n* Complete Accounting\\nContact Us:\\nAddress: 304, PS Continental, 83, 2/1, Topsia Rd, Topsia, Kolkata, West Bengal 700046\\nEmail: info@edominer.com\\nPhone: +91 9007026542\\nProduct Website: https://www.expanderp.com/aboutus/\\nWebsite : https://www.edominer.com/\\n**Ask me anything about eDominer or Expand smERP!**\\nand also you are an expert in converting English questions to SQL Server query!\\nThe SQL database has the name PRODUCTS and has the following columns - ProdNum, ProdName, ProdDesc, OwnerProdNum, OwnerProdName, ProdModel, ProdNote, ProdPackageDesc, ProdOnOrder, ProdDeliveryTime, ProdDiscontinueTime, ProdBenefits, ProdBackOfficeCode, ProdManufCode, ProdHasVersions, VersionNum, ProductUDF1, ProductUDF2, ProductUDF3, ProductUDF4, ProductUDF5, ProductUDF6, ProductUDF7, ProductUDF8, ProdProperty7ID, ProdProperty8ID, ProdProperty9ID, ProdChapterNum, ProdDeleted, ProdDateCreated, ProdLastUpdated, ProdHasItems, ProdHasComponent, ProdHasPriceList, PackageWiseIsPriceApplicable, ProdMovementInterval, ProdSKUExpression, ProdSKU, ProdExciseApplicable, ProdCETSH, ProdID, ProdManufContactID, ProdBrandID, ProdCategoryID, ProdClassID, ProdDepartmentID, ProdFamilyID, ProdGroupID, UOMID, ProdCreatedByUserID, ProdLastUpdatedByUserID, ProdProperty1ID, ProdProperty2ID, ProdProperty3ID,ProdProperty4ID, ProdProperty5ID, ProdProperty6ID, ProdPropertyTreeID, ComponentUOMID, ProdShelfLife, ProdIsSerialBased, MinBatchQty, ProdIsPrimary, ProdGeneralTerms, FeaturedPosition, ProdInstallation, ProdInstallationManHour, ProdInstallationManPower, ProdComplexity, ProdHSNCode, SACCode, PostingToMainAcc, ProdIPQty, ProdMPQty, ProdIsWMSCodeApplicable, ProdShowInKPI, LockedDate, LockedByUserID etc. Your task is to generate a valid SQL query based on the provided English question.\\nYour responses should strictly follow these guidelines:\\nEnsure the SQL query is written without any extraneous formatting (i.e., no markdown, no backticks, no SQL keyword).\\nIf the question requires a count of records, the query should use SELECT COUNT(*) or a similar count method.\\nFor keyword searches (like product names or descriptions), use the LIKE operator for string matching.\\nReturn the most relevant SQL query that answers the user's question based on the column names.\\nFor example,\\nExample 1 - How many entries of records are present?, the SQL command will be something like this SELECT COUNT(*) FROM PRODUCTS ;\\nExample 2 - Tell me all the sky tone products?, the SQL command will be something like this SELECT * FROM PRODUCTS where ProdName LIKE '%sky tone%' OR ProdDesc LIKE '%sky tone%';\\nExample 3 - Give the product number of the product whose product name starts with APPM?, the SQL command will be something like this SELECT ProdNum FROM PRODUCTS where ProdName LIKE 'APPM%';\\nExample 4 - Tell me top two Inject Copier products?, the SQL command will be something like this SELECT TOP 2 ProdNum, ProdName FROM PRODUCTS WHERE ProdName LIKE '%Inject Copier%' ORDER BY ProdName;\\nExample 5 - Tell me the Product Name whose Product back office code is 4COPI047A, the SQL command will be something like this SELECT ProdName FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\\nExample 6 - What is the product name for the product with ProdNum PRO/0278, the SQL command will be something like this SELECT ProdName FROM PRODUCTS WHERE ProdNum = 'PRO/0278';\\nExample 7 - Show me all the products created in the year 2023., the SQL command will be something like this SELECT * FROM PRODUCTS WHERE YEAR(ProdDateCreated) = 2023;\\nExample 8 - Give me the hsn code of sky tone, the SQL command will be something like this SELECT Prod Name, ProdHSNCode FROM PRODUCTS WHERE ProdName LIKE '%sky tone%' OR ProdDesc LIKE '%sky tone%';\\nExample 9 - List the product descriptions for products that have the word 'blue' in their name., the SQL command will be something like this SELECT ProdDesc FROM PRODUCTS WHERE ProdName LIKE '%blue%'; and you can add multiple columns also in sql query for accurate result.\\nExample 10 - Tell me which product has highest entries., the SQL command will be something like this SELECT Top 1 ProdName, COUNT(*) AS EntryCount FROM PRODUCTS GROUP BY ProdName ORDER BY EntryCount DESC;\\nExample 11 - Tell me which product has second highest entries., the SQL command will be something like this WITH RankedProducts AS (SELECT ProdName, COUNT(*) AS EntryCount,ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) AS RowNum FROM PRODUCTS GROUP BY ProdName) SELECT ProdName, EntryCount FROM RankedProducts WHERE RowNum = 2;\\nalso the sql code should not have ``` in the beginning or end and sql word in output\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Deba! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Hi! I'm Deba.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm sorry, I don't have access to personal information. How can I assist you with eDominer or Expand smERP today?\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Our main product is Expand smERP, a cloud-based ERP solution designed to streamline operations for mid-sized Indian manufacturers and exporters. It offers seamless integration with existing business processes, automation of complex tasks, a user-friendly interface, secure data storage on Microsoft Azure, integration with popular platforms like WhatsApp and Paytm, and customizable options to fit specific business needs. How can I help you learn more about Expand smERP?\n"
     ]
    }
   ],
   "source": [
    "query = \"What is your product?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! Here are the pricing details for Expand smERP:\n",
      "1. **Expand eziSales: Lead Management**\n",
      "   - ₹0 per month\n",
      "   - Features: Create Contact (Unlimited), Capture Leads, Create Follow-ups, Mobile Notification, Call Log (Duration Only)\n",
      "   \n",
      "2. **Expand smERP: Enterprise Business**\n",
      "   - ₹2500 per Concurrent User/Month\n",
      "   - Features: Expand Lite + Jobwork, Material Requirement Planning, Multi-Level Approval, Hand-held Terminal App, Customised Reports, Vendor Portal, Workflow Customisation\n",
      "   \n",
      "3. **Expand Lite: Startup Business**\n",
      "   - ₹1800 per Concurrent User/Month\n",
      "   - Features: Lead Management, Sales Planning, Order to Cash, Procure to Pay, Approval Workflow, Product Catalogue, KPI Dashboard, Analytics Dashboard, Complete Accounting\n",
      "\n",
      "Feel free to let me know if you need more information or assistance with our pricing plans!\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you give its pricing?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT ProdName FROM PRODUCTS WHERE ProdNum = 'PRO/0001';\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the product name for the product with ProdNum PRO/0001?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "WITH RankedProducts AS (SELECT ProdName, COUNT(*) AS EntryCount,ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) AS RowNum FROM PRODUCTS GROUP BY ProdName) SELECT Top 1 ProdName, EntryCount FROM RankedProducts;\n"
     ]
    }
   ],
   "source": [
    "query = \"tell me which product has highest entries\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT COUNT(*) FROM PRODUCTS;\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you give its no. of entries?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Conversation History to prevent message Overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"messages\": trimmed_messages}\n",
    "    )\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT ProdName FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"Tell me the Product Name whose Product back office code is 4COPI047A\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT ProdDesc FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"tell its product description\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT UOMID FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"tell its UOMID\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}, id='3189c6fb-5ed4-4fe7-8e6e-87861d5791de'),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}, id='350d2a1a-9ddd-446e-823f-1ff1ba26aab4'),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}, id='453084fb-c8b2-485a-b4fe-64168c9badf2'),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}, id='0317c833-06fa-486d-8428-f1d4bb39f9ae'),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}, id='c23a556b-4cc7-4cf8-8d2b-c7241ddc6b53'),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}, id='1f31377b-e11e-4668-aacd-670de9eaa1c5'),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}, id='715e4c9c-3600-4d12-88b9-e257c3ac8cbc'),\n",
       " HumanMessage(content='tell its UOMID', additional_kwargs={}, response_metadata={}, id='d2cbeab0-69ac-49fb-ab3f-0d66d771c7d9')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(input_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You asked for the UOMID of the product with the back office code '4COPI047A'.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"What SQL query did I ask?\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "SELECT ProdName FROM PRODUCTS WHERE ProdBackOfficeCode = '4COPI047A';\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"Can you give last response?\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Streaming Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|SELECT| *| FROM| PRODUCTS| WHERE| Prod|Date|Created| <| '|202|2|-|01|-|01|';||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"List all products created before 2022-01-01.\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Preference\n",
      "Customer Preference is used to record the unique ‘preferences’ of the Customer such as unique product identifications, customer\n",
      "specific clauses, customer specific charges or opening balances of products with the Customer.\n",
      "How to Create a New Customer Preference?\n",
      "In order to create a NEW Customer Preference the user must go to\n",
      "CRM >> Customer Preference.\n",
      "This opens up the Customer Preference Detail page.\n",
      "Explanations of the various fields in the Customer Preference Detail page:\n",
      "Customer:\n",
      "User must ‘tag’ a Customer in the field labeled Customer.  This is the Customer whose preferences are going to be recorded.\n",
      "This is a mandatory field and the Customer Preference entry cannot be saved without entering this field.\n",
      "Payment Terms\n",
      "The default payment terms for a particular Customer can be tagged in the field labeled Payment Terms.  In order to do this, the\n",
      "user must click on the small icon beside the field to open up a list of pre-configured Payment Terms.  The user must select the\n",
      "appropriate Payment Term and click Ok to finalize the tagging.\n",
      "An example of Payment Terms could be ’90 Days from the Date of Invoice’.\n",
      "The list of pre-configured Payment Terms is created from the Configuration >>> Configuration Center.\n",
      "For a more detailed guide on how to create the list of Payment Terms please refer to the related help.\n",
      "Delivery Terms\n",
      "The default delivery terms for a particular Customer can be tagged in the field labeled Delivery Terms. In order to do this, the\n",
      "user must click on the small icon beside the field to open up a list of pre-configured Delivery Terms.  The user must select the\n",
      "appropriate Delivery Term and click Ok to finalize the tagging.\n",
      "An example of Delivery Terms could be ’Ex - Works’.\n",
      "The list of pre-configured Delivery Terms is created from the Configuration >>> Configuration Center.\n",
      "For a more detailed guide on how to create the list of Delivery Terms please refer to the related help.\n",
      "Inspection Clause\n",
      "The customer when buying goods may have certain terms for inspecting the goods sent to them at their premises.\n",
      "This information can be recorded in the field Inspection Clause. This is a free text field meaning whatever the user types in this\n",
      "field will be reflected in the documents as well.\n",
      "Rejection Clause\n",
      "The customer when buying goods may have certain terms for rejecting the materials.\n",
      "This information can be recorded in the field Rejection Clause. This is a free text field meaning whatever the user types in this\n",
      "field will be reflected in the documents as well.\n",
      "Product\n",
      "Users have the option to link Customers to Products from the Customer Preferences. This enables the user to get a list of all the\n",
      "products, a particular Customer buys vis-a-vis they will also be able to get a list of all the Customers for a particular Product.\n",
      "To do this the User must click on the ‘Add’ button on the Product tab in the child section. This will open up a window with all\n",
      "the available Products. User must select the required product and click ok to finalize the selection.\n",
      "Once the product appears on the screen users can click on ‘Save’ to save the Customer Preference or they can specify more\n",
      "details mentioned below:\n",
      "Alternate No.\n",
      "The Alternate No. field is useful if the Customer identifies the Product through an alternate Product No. other than the one\n",
      "specified in the Product Master.\n",
      "Alternate Description\n",
      "The Alternate Description field is useful if the Customer identifies an alternate Product Description other than the one which is\n",
      "specified in the Product Master.\n",
      "Lead Time (Days)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(r\"C:\\Users\\eDominer\\Python Project\\ChatBot\\ChatBot_with_Database\\OpenAI Tuned Model\\Help_whole.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "# print(docs[168])\n",
    "\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 3557\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 746 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data into Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "# Initialize with an embedding model\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['09f89bb5-091b-43a5-b618-cabfcbfb79bb', '2ef40805-73ca-48da-a8f5-ea5d66b230f3', 'ae687848-d230-41b8-be2d-14c57735273b']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eDominer\\anaconda3\\envs\\py310\\lib\\site-packages\\langsmith\\client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Preference is used to record unique preferences of a customer, such as product identifications and specific charges. To create a new Customer Preference, go to CRM and click on Customer Preference to open the Customer Preference Detail page. In this page, you can add the required customer and enter details like Payment Terms, Inspection Clause, and Delivery Terms.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Customer Preference?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a new customer preference, go to CRM and click on Customer Preference. Add the required customer in the customer field. Verify all the data and click on 'Save' to complete the process.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to Create a New Customer Preference?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a Machine master, go to the Machine menu in the Business Definition module. Click on the New button to create a new machine master. Fill in details like Machine No., Machine Name, and other relevant information in the basic and advance tabs. Save the information to successfully create the Machine master.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to Create Machine master?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a contact in the system, go to CRM, click on Contact, then New, and enter the contact name. Add phone number, address, and email details in the respective tabs. Once all relevant data is entered, click on Save to create the contact.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to create contact?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create an Export Invoice, go to the Export module, click on Export Invoice/Packing List, and select New. Fill in the required details in the Basic, Advance, and Buyer Detail tabs. Save the file in CSV format and upload it to the GST Offline Tool for further processing.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to create Export Invoice?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a PI/LC document, go to the Export Module, click on the PI/LC menu in Export Orders, and select New. Enter the required details such as Customer PO No, Ref Date, Payment Terms, Delivery Terms, and Currency. Add bank details, LC details, and LC terms as needed in the respective tabs.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"How to create  PI/LC document?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "WITH RankedProducts AS (SELECT ProdName, COUNT(*) AS EntryCount,ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) AS RowNum FROM PRODUCTS GROUP BY ProdName) SELECT Top 1 ProdName, EntryCount FROM RankedProducts;\n"
     ]
    }
   ],
   "source": [
    "query = \"tell me which product has highest entries\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='tell me which product has highest entries', additional_kwargs={}, response_metadata={}, id='67533d5a-e980-44cf-be04-6b3729985afd')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
