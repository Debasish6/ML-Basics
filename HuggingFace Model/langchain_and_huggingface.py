# -*- coding: utf-8 -*-
"""LangChain and Huggingface.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pw1MPyvJ937H_2Hpg6BV2n30ruUhiSfE
"""

!pip install langchain-huggingface
!pip install huggingface_hub
!pip install transformers
!pip install accelerate
!pip install bitsandbytes
!pip install langchain

from google.colab import userdata
import os
huggingface_token = userdata.get('HUGGINGFACEHUB_API_TOKEN')

print(huggingface_token)

"""# Accessing Huggingface models using API"""

from langchain_huggingface import HuggingFaceEndpoint

import os
os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_token

repo_id = "meta-llama/Llama-3.1-8B-Instruct"
llm = HuggingFaceEndpoint(repo_id=repo_id, max_length= 128,temperature= 0.7, task = "text-generation",token=huggingface_token)

llm

predict = llm.invoke("What is Machine Learning")

import markdown

http = markdown.markdown(predict)

http

predict

from langchain import PromptTemplate, LLMChain

query = "What is GenAI?"
template = """Question: {Question}"""

prompt=PromptTemplate(input_variables=["Question"],template=template)
print(prompt)

llm_chain = LLMChain(prompt=prompt, llm=llm)
llm_chain.invoke(query)

"""# HuggingFace Pipeline"""

from langchain_huggingface import HuggingFacePipeline
from transformers import AutoModelForCausalLM , AutoTokenizer, pipeline

model_id = "gpt2"
model = AutoModelForCausalLM.from_pretrained(model_id)
tokenizer = AutoTokenizer.from_pretrained(model_id)

pipe = pipeline(task = "text-generation" ,model=model,tokenizer=tokenizer)

hf = HuggingFacePipeline(pipeline=pipe)

hf.invoke("Who is Java?")

gpu_llm = HuggingFacePipeline.from_model_id(model_id='gpt2',task="text-generation",device=0,pipeline_kwargs={"max_new_tokens":100},)

from langchain_core.prompts import PromptTemplate

template = """Question: {Question}
Answer: """

prompt=PromptTemplate.from_template(template)

chain = prompt|gpu_llm    # It is another way of creating chain

question = "What is GenAI?"
chain.invoke({"Question":question})

